{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"D:/Inmovidu/myData\"\n",
    "labelsFile=\"D:/Inmovidu/labels.csv\"\n",
    "images=[]\n",
    "classNo=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Classes...\n",
      "0  Done\n",
      "1  Done\n",
      "2  Done\n",
      "3  Done\n",
      "4  Done\n",
      "5  Done\n",
      "6  Done\n",
      "7  Done\n",
      "8  Done\n",
      "9  Done\n",
      "10  Done\n",
      "11  Done\n",
      "12  Done\n",
      "13  Done\n",
      "14  Done\n",
      "15  Done\n",
      "16  Done\n",
      "17  Done\n",
      "18  Done\n",
      "19  Done\n",
      "20  Done\n",
      "21  Done\n",
      "22  Done\n",
      "23  Done\n",
      "24  Done\n",
      "25  Done\n",
      "26  Done\n",
      "27  Done\n",
      "28  Done\n",
      "29  Done\n",
      "30  Done\n",
      "31  Done\n",
      "32  Done\n",
      "33  Done\n",
      "34  Done\n",
      "35  Done\n",
      "36  Done\n",
      "37  Done\n",
      "38  Done\n",
      "39  Done\n",
      "40  Done\n",
      "41  Done\n",
      "42  Done\n"
     ]
    }
   ],
   "source": [
    "myList=os.listdir(path)\n",
    "noOfClasses=len(myList)\n",
    "\n",
    "print(\"Importing Classes...\")\n",
    "for i in range(0,noOfClasses):\n",
    "    myPicList=os.listdir(path + \"/\" + str(i))\n",
    "    for y in myPicList:\n",
    "        Img=cv2.imread(path + \"/\" + str(i) + \"/\" + y)\n",
    "        Img=cv2.cvtColor(Img,cv2.COLOR_BGR2GRAY)\n",
    "        images.append(Img)\n",
    "        classNo.append(i)\n",
    "    print(i, \" Done\")\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.array(images)\n",
    "classNo=np.array(classNo)\n",
    "images=images/255.0\n",
    "train_features,test_features,train_target,test_target=train_test_split(images,classNo,test_size=0.2)\n",
    "train_features=train_features.reshape(train_features.shape[0], train_features.shape[1],train_features.shape[2],1)\n",
    "test_features=test_features.reshape(test_features.shape[0],test_features.shape[1],test_features.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataGenerator=ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1,zoom_range=0.2,shear_range=0.1,rotation_range=10)\n",
    "dataGenerator.fit(train_features)\n",
    "batches=dataGenerator.flow(train_features,train_target,batch_size=20)\n",
    "train_target=to_categorical(train_target,noOfClasses)\n",
    "test_target=to_categorical(test_target,noOfClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(64,(3,3),activation=\"relu\",input_shape=(32, 32, 1)))\n",
    "model.add(Conv2D(64,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(128,(3,3),activation=\"relu\"))\n",
    "model.add(Conv2D(128,(3,3),activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "model.add(Dense(noOfClasses,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vasub\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "557/557 [==============================] - 117s 209ms/step - loss: 2.8290 - accuracy: 0.2340\n",
      "Epoch 2/30\n",
      "557/557 [==============================] - 119s 214ms/step - loss: 0.6290 - accuracy: 0.8092\n",
      "Epoch 3/30\n",
      "557/557 [==============================] - 119s 213ms/step - loss: 0.3224 - accuracy: 0.8989\n",
      "Epoch 4/30\n",
      "557/557 [==============================] - 119s 214ms/step - loss: 0.2202 - accuracy: 0.9321\n",
      "Epoch 5/30\n",
      "557/557 [==============================] - 119s 213ms/step - loss: 0.1712 - accuracy: 0.9459\n",
      "Epoch 6/30\n",
      "557/557 [==============================] - 117s 211ms/step - loss: 0.1388 - accuracy: 0.9566\n",
      "Epoch 7/30\n",
      "557/557 [==============================] - 117s 210ms/step - loss: 0.1098 - accuracy: 0.9663\n",
      "Epoch 8/30\n",
      "557/557 [==============================] - 118s 212ms/step - loss: 0.1044 - accuracy: 0.9684\n",
      "Epoch 9/30\n",
      "557/557 [==============================] - 121s 218ms/step - loss: 0.0901 - accuracy: 0.9719\n",
      "Epoch 10/30\n",
      "557/557 [==============================] - 119s 213ms/step - loss: 0.0871 - accuracy: 0.9733\n",
      "Epoch 11/30\n",
      "557/557 [==============================] - 119s 213ms/step - loss: 0.0761 - accuracy: 0.9771\n",
      "Epoch 12/30\n",
      "557/557 [==============================] - 119s 213ms/step - loss: 0.0822 - accuracy: 0.9740\n",
      "Epoch 13/30\n",
      "557/557 [==============================] - 118s 213ms/step - loss: 0.0660 - accuracy: 0.9795\n",
      "Epoch 14/30\n",
      "557/557 [==============================] - 119s 213ms/step - loss: 0.0652 - accuracy: 0.9800\n",
      "Epoch 15/30\n",
      "557/557 [==============================] - 120s 216ms/step - loss: 0.0662 - accuracy: 0.9807\n",
      "Epoch 16/30\n",
      "557/557 [==============================] - 121s 216ms/step - loss: 0.0592 - accuracy: 0.9817\n",
      "Epoch 17/30\n",
      "557/557 [==============================] - 121s 218ms/step - loss: 0.0547 - accuracy: 0.9822\n",
      "Epoch 18/30\n",
      "557/557 [==============================] - 141s 252ms/step - loss: 0.0460 - accuracy: 0.9854\n",
      "Epoch 19/30\n",
      "557/557 [==============================] - 114s 205ms/step - loss: 0.0490 - accuracy: 0.9838\n",
      "Epoch 20/30\n",
      "557/557 [==============================] - 111s 200ms/step - loss: 0.0567 - accuracy: 0.9818\n",
      "Epoch 21/30\n",
      "557/557 [==============================] - 108s 194ms/step - loss: 0.0471 - accuracy: 0.9857\n",
      "Epoch 22/30\n",
      "557/557 [==============================] - 114s 204ms/step - loss: 0.0470 - accuracy: 0.9847\n",
      "Epoch 23/30\n",
      "557/557 [==============================] - 117s 210ms/step - loss: 0.0443 - accuracy: 0.9864\n",
      "Epoch 24/30\n",
      "557/557 [==============================] - 118s 212ms/step - loss: 0.0417 - accuracy: 0.9870\n",
      "Epoch 25/30\n",
      "557/557 [==============================] - 116s 207ms/step - loss: 0.0525 - accuracy: 0.9847\n",
      "Epoch 26/30\n",
      "557/557 [==============================] - 116s 209ms/step - loss: 0.0381 - accuracy: 0.9885\n",
      "Epoch 27/30\n",
      "557/557 [==============================] - 115s 207ms/step - loss: 0.0365 - accuracy: 0.9895\n",
      "Epoch 28/30\n",
      "557/557 [==============================] - 113s 204ms/step - loss: 0.0417 - accuracy: 0.9878\n",
      "Epoch 29/30\n",
      "557/557 [==============================] - 116s 208ms/step - loss: 0.0407 - accuracy: 0.9871\n",
      "Epoch 30/30\n",
      "557/557 [==============================] - 116s 208ms/step - loss: 0.0364 - accuracy: 0.9897\n"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "fitted_model=model.fit_generator(dataGenerator.flow(train_features,train_target,batch_size=50),epochs=30)\n",
    "model.save('Traffic_Sign_Classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model('Traffic_Sign_Classifier.h5')\n",
    "def getCalssName(classNo):\n",
    "    if   classNo == 0: return 'Speed Limit 20 km/h'\n",
    "    elif classNo == 1: return 'Speed Limit 30 km/h'\n",
    "    elif classNo == 2: return 'Speed Limit 50 km/h'\n",
    "    elif classNo == 3: return 'Speed Limit 60 km/h'\n",
    "    elif classNo == 4: return 'Speed Limit 70 km/h'\n",
    "    elif classNo == 5: return 'Speed Limit 80 km/h'\n",
    "    elif classNo == 6: return 'End of Speed Limit 80 km/h'\n",
    "    elif classNo == 7: return 'Speed Limit 100 km/h'\n",
    "    elif classNo == 8: return 'Speed Limit 120 km/h'\n",
    "    elif classNo == 9: return 'No passing'\n",
    "    elif classNo == 10: return 'No passing for vechiles over 3.5 metric tons'\n",
    "    elif classNo == 11: return 'Right-of-way at the next intersection'\n",
    "    elif classNo == 12: return 'Priority road'\n",
    "    elif classNo == 13: return 'Yield'\n",
    "    elif classNo == 14: return 'Stop'\n",
    "    elif classNo == 15: return 'No vechiles'\n",
    "    elif classNo == 16: return 'Vechiles over 3.5 metric tons prohibited'\n",
    "    elif classNo == 17: return 'No entry'\n",
    "    elif classNo == 18: return 'General caution'\n",
    "    elif classNo == 19: return 'Dangerous curve to the left'\n",
    "    elif classNo == 20: return 'Dangerous curve to the right'\n",
    "    elif classNo == 21: return 'Double curve'\n",
    "    elif classNo == 22: return 'Bumpy road'\n",
    "    elif classNo == 23: return 'Slippery road'\n",
    "    elif classNo == 24: return 'Road narrows on the right'\n",
    "    elif classNo == 25: return 'Road work'\n",
    "    elif classNo == 26: return 'Traffic signals'\n",
    "    elif classNo == 27: return 'Pedestrians'\n",
    "    elif classNo == 28: return 'Children crossing'\n",
    "    elif classNo == 29: return 'Bicycles crossing'\n",
    "    elif classNo == 30: return 'Beware of ice/snow'\n",
    "    elif classNo == 31: return 'Wild animals crossing'\n",
    "    elif classNo == 32: return 'End of all speed and passing limits'\n",
    "    elif classNo == 33: return 'Turn right ahead'\n",
    "    elif classNo == 34: return 'Turn left ahead'\n",
    "    elif classNo == 35: return 'Ahead only'\n",
    "    elif classNo == 36: return 'Go straight or right'\n",
    "    elif classNo == 37: return 'Go straight or left'\n",
    "    elif classNo == 38: return 'Keep right'\n",
    "    elif classNo == 39: return 'Keep left'\n",
    "    elif classNo == 40: return 'Roundabout mandatory'\n",
    "    elif classNo == 41: return 'End of no passing'\n",
    "    elif classNo == 42: return 'End of no passing by vechiles over 3.5 metric tons'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cap=cv2.VideoCapture(0)\n",
    "cap.set(3,640)\n",
    "cap.set(4,480)\n",
    "cap.set(10,180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "import numpy as np\n",
    "while True:\n",
    "    success,image=cap.read()\n",
    "    img=np.asarray(image)\n",
    "    grayscale=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    grayscale=cv2.resize(grayscale,(32,32))\n",
    "    equalised_img=cv2.equalizeHist(grayscale)\n",
    "    normalised_img=equalised_img/255\n",
    "    normalised_img=normalised_img.reshape(32,32,1)\n",
    "    final_img=np.reshape(normalised_img,(1,32,32,1))\n",
    "    cv2.putText(image,\"Class: \",(20,35),font,0.75,(255,0,0),2,cv2.LINE_AA)\n",
    "    cv2.putText(image,\"Probability: \",(20,75),font,0.75,(255,0,0),2,cv2.LINE_AA)\n",
    "    predictions=model.predict(final_img)\n",
    "    classIndex=model.predict_classes(final_img)\n",
    "    probabilityValue=np.amax(predictions)\n",
    "    if probabilityValue>0.75:\n",
    "        cv2.putText(image,str(classIndex) + \" \"+ str(getCalssName(classIndex)),(120,35),font,0.75,(255,122,0),2,cv2.LINE_AA)\n",
    "        cv2.putText(image,str(round(probabilityValue*100,2)) + \"%\",(120,150),font,0.75,(255,122,0),2,cv2.LINE_AA)\n",
    "    cv2.imshow(\"Result\",image)\n",
    "    if cv2.waitKey(1)==113:\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
